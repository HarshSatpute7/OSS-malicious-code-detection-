{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from imutils import paths\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/FlipKart_GRID/archive/data/New folder/b1',\n",
       " 'D:/FlipKart_GRID/archive/data/New folder/m1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"D:/FlipKart_GRID/archive/data/New folder\"\n",
    "LABELS = list(['b1', 'm1'])\n",
    "paths_ = []\n",
    "for i in LABELS:\n",
    "  paths_.append(path+'/'+i)\n",
    "paths_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagepaths = []\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(len(paths_)):\n",
    "  imagepaths = list(paths.list_images(paths_[i]))\n",
    "  for imagepath in imagepaths:\n",
    "    #print(imagepath)\n",
    "    label = imagepath.split(os.path.sep)[-2]\n",
    "    #print(label)\n",
    "    image = cv2.imread(imagepath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size = 0.25, stratify = labels, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "traininAugmentation = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,horizontal_flip=True,fill_mode=\"nearest\")\n",
    "\n",
    "validationAugmentation = ImageDataGenerator()\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype = \"float32\")\n",
    "traininAugmentation.mean = mean\n",
    "validationAugmentation.mean = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, AveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(weights = 'imagenet', input_shape = (224, 224, 3), include_top = False)\n",
    "resnet_last_layer = AveragePooling2D(pool_size=(7,7))(resnet.output)\n",
    "resnet_last_layer = Flatten()(resnet_last_layer)\n",
    "resnet_last_layer = Dense(1024, activation='relu')(resnet_last_layer)\n",
    "resnet_last_layer = Dropout(0.5)(resnet_last_layer)\n",
    "resnet_last_layer = Dense(1024, activation='relu')(resnet_last_layer)\n",
    "resnet_last_layer = Dropout(0.3)(resnet_last_layer)\n",
    "resnet_last_layer = Dense(512, activation='relu')(resnet_last_layer)\n",
    "resnet_last_layer = Dropout(0.2)(resnet_last_layer)\n",
    "resnet_last_layer = Dense(2, activation='sigmoid')(resnet_last_layer)\n",
    "model = Model(inputs = resnet.input, outputs = resnet_last_layer)\n",
    "\n",
    "for layer in resnet.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "adam = Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08)\n",
    "sgd = SGD(learning_rate = 0.0001, momentum = 0.9, decay = 1e-4/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('best_model_resnet.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham Satpute\\AppData\\Local\\Temp\\ipykernel_20688\\1955056854.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7507 - accuracy: 0.2760\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.42188, saving model to best_model_resnet.h5\n",
      "6/6 [==============================] - 28s 4s/step - loss: 0.7507 - accuracy: 0.2760 - val_loss: 0.4139 - val_accuracy: 0.4219\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.4826\n",
      "Epoch 00002: val_accuracy improved from 0.42188 to 0.45312, saving model to best_model_resnet.h5\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.4624 - accuracy: 0.4826 - val_loss: 0.3431 - val_accuracy: 0.4531\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.4479\n",
      "Epoch 00003: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3805 - accuracy: 0.4479 - val_loss: 0.2718 - val_accuracy: 0.4219\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.4186\n",
      "Epoch 00004: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.3952 - accuracy: 0.4186 - val_loss: 0.3097 - val_accuracy: 0.4219\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.4244\n",
      "Epoch 00005: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 21s 4s/step - loss: 0.3538 - accuracy: 0.4244 - val_loss: 0.2846 - val_accuracy: 0.4375\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.4477\n",
      "Epoch 00006: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3557 - accuracy: 0.4477 - val_loss: 0.2895 - val_accuracy: 0.4219\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.4419\n",
      "Epoch 00007: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.3775 - accuracy: 0.4419 - val_loss: 0.3013 - val_accuracy: 0.4219\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.3953\n",
      "Epoch 00008: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 21s 4s/step - loss: 0.3210 - accuracy: 0.3953 - val_loss: 0.2974 - val_accuracy: 0.4219\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    traininAugmentation.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch = len(X_train) // 32,\n",
    "    validation_data = validationAugmentation.flow(X_test,y_test),\n",
    "    validation_steps = len(X_test) // 32,\n",
    "    epochs = 25, callbacks = [es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 1s/step - loss: 0.2826 - accuracy: 0.4203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28255805373191833, 0.4202898442745209]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 29s 0us/step\n",
      "80150528/80134624 [==============================] - 29s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg19 = VGG19(weights = 'imagenet', input_shape = (224, 224, 3), include_top = False)\n",
    "vgg_last_layer = GlobalAveragePooling2D()(vgg19.output)\n",
    "vgg_last_layer = Flatten()(vgg_last_layer)\n",
    "vgg_last_layer = Dense(1024, activation='relu')(vgg_last_layer)\n",
    "vgg_last_layer = Dropout(0.5)(vgg_last_layer)\n",
    "vgg_last_layer = Dense(1024, activation='relu')(vgg_last_layer)\n",
    "vgg_last_layer = Dropout(0.3)(vgg_last_layer)\n",
    "vgg_last_layer = Dense(512, activation='relu')(vgg_last_layer)\n",
    "vgg_last_layer = Dropout(0.2)(vgg_last_layer)\n",
    "vgg_last_layer = Dense(2, activation='sigmoid')(vgg_last_layer)\n",
    "model = Model(inputs = vgg19.input, outputs = vgg_last_layer)\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "#mobile = MobileNet(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
    "#vgg = tf.keras.applications.vgg16.VGG16(input_shape=(224,224,3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "adam = Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = adam, metrics = [\"accuracy\"])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham Satpute\\AppData\\Local\\Temp\\ipykernel_20688\\472305448.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.8915 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.40625, saving model to best_model.h5\n",
      "6/6 [==============================] - 53s 8s/step - loss: 1.8915 - accuracy: 0.5000 - val_loss: 0.3662 - val_accuracy: 0.4062\n",
      "Epoch 2/8\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1211 - accuracy: 0.3779\n",
      "Epoch 00002: val_accuracy improved from 0.40625 to 0.43750, saving model to best_model.h5\n",
      "6/6 [==============================] - 53s 10s/step - loss: 1.1211 - accuracy: 0.3779 - val_loss: 0.3355 - val_accuracy: 0.4375\n",
      "Epoch 3/8\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9520 - accuracy: 0.4896\n",
      "Epoch 00003: val_accuracy did not improve from 0.43750\n",
      "6/6 [==============================] - 57s 10s/step - loss: 0.9520 - accuracy: 0.4896 - val_loss: 0.3785 - val_accuracy: 0.4219\n",
      "Epoch 4/8\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7989 - accuracy: 0.4070\n",
      "Epoch 00004: val_accuracy did not improve from 0.43750\n",
      "6/6 [==============================] - 55s 9s/step - loss: 0.7989 - accuracy: 0.4070 - val_loss: 0.4319 - val_accuracy: 0.4219\n",
      "Epoch 5/8\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8419 - accuracy: 0.4419\n",
      "Epoch 00005: val_accuracy improved from 0.43750 to 0.45312, saving model to best_model.h5\n",
      "6/6 [==============================] - 56s 10s/step - loss: 0.8419 - accuracy: 0.4419 - val_loss: 0.3840 - val_accuracy: 0.4531\n",
      "Epoch 6/8\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.4477\n",
      "Epoch 00006: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 54s 9s/step - loss: 0.5768 - accuracy: 0.4477 - val_loss: 0.4084 - val_accuracy: 0.4375\n",
      "Epoch 7/8\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.4535\n",
      "Epoch 00007: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 55s 9s/step - loss: 0.6349 - accuracy: 0.4535 - val_loss: 0.3103 - val_accuracy: 0.4062\n",
      "Epoch 8/8\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.5000\n",
      "Epoch 00008: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 56s 10s/step - loss: 0.6952 - accuracy: 0.5000 - val_loss: 0.3602 - val_accuracy: 0.4531\n"
     ]
    }
   ],
   "source": [
    "#model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "history = model.fit_generator(\n",
    "    traininAugmentation.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch = len(X_train) // 32,\n",
    "    validation_data = validationAugmentation.flow(X_test,y_test),\n",
    "    validation_steps = len(X_test) // 32,\n",
    "    epochs = 8, callbacks = [es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 14s 3s/step - loss: 0.3956 - accuracy: 0.4203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39558184146881104, 0.4202898442745209]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 9s 1us/step\n",
      "17235968/17225924 [==============================] - 9s 1us/step\n"
     ]
    }
   ],
   "source": [
    "mobile_net = MobileNet(weights = 'imagenet', input_shape = (224, 224, 3), include_top = False)\n",
    "mn_last_layer = GlobalAveragePooling2D()(mobile_net.output)\n",
    "mn_last_layer = Flatten()(mn_last_layer)\n",
    "mn_last_layer = Dense(1024, activation='relu')(mn_last_layer)\n",
    "mn_last_layer = Dropout(0.5)(mn_last_layer)\n",
    "mn_last_layer = Dense(1024, activation='relu')(mn_last_layer)\n",
    "mn_last_layer = Dropout(0.3)(mn_last_layer)\n",
    "mn_last_layer = Dense(512, activation='relu')(mn_last_layer)\n",
    "mn_last_layer = Dropout(0.2)(mn_last_layer)\n",
    "mn_last_layer = Dense(2, activation='sigmoid')(mn_last_layer)\n",
    "model = Model(inputs = mobile_net.input, outputs = mn_last_layer)\n",
    "\n",
    "for layer in mobile_net.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "adam = Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = adam, metrics = [\"accuracy\"])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham Satpute\\AppData\\Local\\Temp\\ipykernel_20688\\85072829.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.3256\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.45312, saving model to best_model.h5\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.6633 - accuracy: 0.3256 - val_loss: 0.5098 - val_accuracy: 0.4531\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.4323\n",
      "Epoch 00002: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.5999 - accuracy: 0.4323 - val_loss: 0.3649 - val_accuracy: 0.3906\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.4535\n",
      "Epoch 00003: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.4286 - accuracy: 0.4535 - val_loss: 0.2771 - val_accuracy: 0.3750\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.4012\n",
      "Epoch 00004: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.4205 - accuracy: 0.4012 - val_loss: 0.2801 - val_accuracy: 0.4062\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.4651\n",
      "Epoch 00005: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.4008 - accuracy: 0.4651 - val_loss: 0.2977 - val_accuracy: 0.3906\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.4535\n",
      "Epoch 00006: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.4113 - accuracy: 0.4535 - val_loss: 0.2373 - val_accuracy: 0.3750\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.4012\n",
      "Epoch 00007: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3048 - accuracy: 0.4012 - val_loss: 0.3141 - val_accuracy: 0.3750\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.4062\n",
      "Epoch 00008: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.3900 - accuracy: 0.4062 - val_loss: 0.2999 - val_accuracy: 0.3750\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3478 - accuracy: 0.4767\n",
      "Epoch 00009: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3478 - accuracy: 0.4767 - val_loss: 0.2994 - val_accuracy: 0.4062\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4273 - accuracy: 0.5116\n",
      "Epoch 00010: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.4273 - accuracy: 0.5116 - val_loss: 0.2767 - val_accuracy: 0.4062\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.4651\n",
      "Epoch 00011: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.3245 - accuracy: 0.4651 - val_loss: 0.3411 - val_accuracy: 0.3906\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.4302\n",
      "Epoch 00012: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.3379 - accuracy: 0.4302 - val_loss: 0.3167 - val_accuracy: 0.4062\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.4535\n",
      "Epoch 00013: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3900 - accuracy: 0.4535 - val_loss: 0.3001 - val_accuracy: 0.3906\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.4115\n",
      "Epoch 00014: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3262 - accuracy: 0.4115 - val_loss: 0.3158 - val_accuracy: 0.3906\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.4115\n",
      "Epoch 00015: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2975 - accuracy: 0.4115 - val_loss: 0.2612 - val_accuracy: 0.4062\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.4593\n",
      "Epoch 00016: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3428 - accuracy: 0.4593 - val_loss: 0.3112 - val_accuracy: 0.3750\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.4128\n",
      "Epoch 00017: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3274 - accuracy: 0.4128 - val_loss: 0.2919 - val_accuracy: 0.3750\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.3837\n",
      "Epoch 00018: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.3081 - accuracy: 0.3837 - val_loss: 0.3078 - val_accuracy: 0.3750\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.4651\n",
      "Epoch 00019: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2778 - accuracy: 0.4651 - val_loss: 0.2261 - val_accuracy: 0.3906\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.4419\n",
      "Epoch 00020: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2747 - accuracy: 0.4419 - val_loss: 0.2976 - val_accuracy: 0.3750\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.4244\n",
      "Epoch 00021: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3746 - accuracy: 0.4244 - val_loss: 0.2748 - val_accuracy: 0.4219\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.4651\n",
      "Epoch 00022: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3327 - accuracy: 0.4651 - val_loss: 0.3000 - val_accuracy: 0.3750\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.4244\n",
      "Epoch 00023: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.3278 - accuracy: 0.4244 - val_loss: 0.3049 - val_accuracy: 0.4062\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.4360\n",
      "Epoch 00024: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3458 - accuracy: 0.4360 - val_loss: 0.2710 - val_accuracy: 0.4062\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.4012\n",
      "Epoch 00025: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3146 - accuracy: 0.4012 - val_loss: 0.3141 - val_accuracy: 0.4062\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3337 - accuracy: 0.4651\n",
      "Epoch 00026: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3337 - accuracy: 0.4651 - val_loss: 0.2777 - val_accuracy: 0.4062\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.3895\n",
      "Epoch 00027: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 980ms/step - loss: 0.3481 - accuracy: 0.3895 - val_loss: 0.2670 - val_accuracy: 0.3750\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.4427\n",
      "Epoch 00028: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3460 - accuracy: 0.4427 - val_loss: 0.2794 - val_accuracy: 0.4219\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.4844\n",
      "Epoch 00029: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2992 - accuracy: 0.4844 - val_loss: 0.2868 - val_accuracy: 0.4062\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.4419\n",
      "Epoch 00030: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3390 - accuracy: 0.4419 - val_loss: 0.2970 - val_accuracy: 0.3906\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.3779\n",
      "Epoch 00031: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3481 - accuracy: 0.3779 - val_loss: 0.2491 - val_accuracy: 0.4375\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2914 - accuracy: 0.4709\n",
      "Epoch 00032: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2914 - accuracy: 0.4709 - val_loss: 0.2134 - val_accuracy: 0.4219\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3338 - accuracy: 0.4302\n",
      "Epoch 00033: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 955ms/step - loss: 0.3338 - accuracy: 0.4302 - val_loss: 0.2673 - val_accuracy: 0.4062\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.4244\n",
      "Epoch 00034: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 947ms/step - loss: 0.3043 - accuracy: 0.4244 - val_loss: 0.2329 - val_accuracy: 0.4375\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.4709\n",
      "Epoch 00035: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 978ms/step - loss: 0.3716 - accuracy: 0.4709 - val_loss: 0.2421 - val_accuracy: 0.4062\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.4128\n",
      "Epoch 00036: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3251 - accuracy: 0.4128 - val_loss: 0.3034 - val_accuracy: 0.3750\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.4186\n",
      "Epoch 00037: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3521 - accuracy: 0.4186 - val_loss: 0.2172 - val_accuracy: 0.4375\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3107 - accuracy: 0.4896\n",
      "Epoch 00038: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3107 - accuracy: 0.4896 - val_loss: 0.2982 - val_accuracy: 0.3906\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.4302\n",
      "Epoch 00039: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 941ms/step - loss: 0.3121 - accuracy: 0.4302 - val_loss: 0.3186 - val_accuracy: 0.3906\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.4128\n",
      "Epoch 00040: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 941ms/step - loss: 0.3622 - accuracy: 0.4128 - val_loss: 0.2490 - val_accuracy: 0.4062\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.4767\n",
      "Epoch 00041: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.2763 - accuracy: 0.4767 - val_loss: 0.2569 - val_accuracy: 0.3906\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3098 - accuracy: 0.4651\n",
      "Epoch 00042: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3098 - accuracy: 0.4651 - val_loss: 0.2644 - val_accuracy: 0.3906\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.3906\n",
      "Epoch 00043: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2953 - accuracy: 0.3906 - val_loss: 0.2587 - val_accuracy: 0.3750\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.3953\n",
      "Epoch 00044: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2985 - accuracy: 0.3953 - val_loss: 0.2923 - val_accuracy: 0.3438\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.4477\n",
      "Epoch 00045: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3306 - accuracy: 0.4477 - val_loss: 0.3069 - val_accuracy: 0.3750\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.4360\n",
      "Epoch 00046: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 954ms/step - loss: 0.3217 - accuracy: 0.4360 - val_loss: 0.2855 - val_accuracy: 0.3906\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.4419\n",
      "Epoch 00047: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3162 - accuracy: 0.4419 - val_loss: 0.2414 - val_accuracy: 0.4219\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.4767\n",
      "Epoch 00048: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2729 - accuracy: 0.4767 - val_loss: 0.2688 - val_accuracy: 0.4219\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.4709\n",
      "Epoch 00049: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2694 - accuracy: 0.4709 - val_loss: 0.2761 - val_accuracy: 0.4375\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.4360\n",
      "Epoch 00050: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2963 - accuracy: 0.4360 - val_loss: 0.3173 - val_accuracy: 0.3750\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.4128\n",
      "Epoch 00051: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3254 - accuracy: 0.4128 - val_loss: 0.3067 - val_accuracy: 0.3906\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.4419\n",
      "Epoch 00052: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3141 - accuracy: 0.4419 - val_loss: 0.3009 - val_accuracy: 0.3750\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.4535\n",
      "Epoch 00053: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2783 - accuracy: 0.4535 - val_loss: 0.3413 - val_accuracy: 0.3906\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.3663\n",
      "Epoch 00054: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3334 - accuracy: 0.3663 - val_loss: 0.3303 - val_accuracy: 0.3750\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.4302\n",
      "Epoch 00055: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.3114 - accuracy: 0.4302 - val_loss: 0.2994 - val_accuracy: 0.4062\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.4302\n",
      "Epoch 00056: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.2742 - accuracy: 0.4302 - val_loss: 0.3008 - val_accuracy: 0.3906\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.4302\n",
      "Epoch 00057: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.3286 - accuracy: 0.4302 - val_loss: 0.2995 - val_accuracy: 0.4062\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.4477\n",
      "Epoch 00058: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2658 - accuracy: 0.4477 - val_loss: 0.2767 - val_accuracy: 0.3750\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.4477\n",
      "Epoch 00059: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.2801 - accuracy: 0.4477 - val_loss: 0.2943 - val_accuracy: 0.3750\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.4302\n",
      "Epoch 00060: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.3121 - accuracy: 0.4302 - val_loss: 0.3169 - val_accuracy: 0.3594\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.4360\n",
      "Epoch 00061: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.2560 - accuracy: 0.4360 - val_loss: 0.3041 - val_accuracy: 0.3750\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.4186\n",
      "Epoch 00062: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.3175 - accuracy: 0.4186 - val_loss: 0.2908 - val_accuracy: 0.3750\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.4302\n",
      "Epoch 00063: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3015 - accuracy: 0.4302 - val_loss: 0.2609 - val_accuracy: 0.4062\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.4477\n",
      "Epoch 00064: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.2516 - accuracy: 0.4477 - val_loss: 0.2843 - val_accuracy: 0.3906\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3061 - accuracy: 0.4012\n",
      "Epoch 00065: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3061 - accuracy: 0.4012 - val_loss: 0.3154 - val_accuracy: 0.3750\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2788 - accuracy: 0.4593\n",
      "Epoch 00066: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.2788 - accuracy: 0.4593 - val_loss: 0.2928 - val_accuracy: 0.3906\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.5000\n",
      "Epoch 00067: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3032 - accuracy: 0.5000 - val_loss: 0.2777 - val_accuracy: 0.4062\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.5000\n",
      "Epoch 00068: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2795 - accuracy: 0.5000 - val_loss: 0.3285 - val_accuracy: 0.3750\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.4070\n",
      "Epoch 00069: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3019 - accuracy: 0.4070 - val_loss: 0.3382 - val_accuracy: 0.3594\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.4651\n",
      "Epoch 00070: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3256 - accuracy: 0.4651 - val_loss: 0.2669 - val_accuracy: 0.3906\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.4884\n",
      "Epoch 00071: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2595 - accuracy: 0.4884 - val_loss: 0.2538 - val_accuracy: 0.3594\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.4128\n",
      "Epoch 00072: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3199 - accuracy: 0.4128 - val_loss: 0.2577 - val_accuracy: 0.3750\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.4535\n",
      "Epoch 00073: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 2s/step - loss: 0.3177 - accuracy: 0.4535 - val_loss: 0.2653 - val_accuracy: 0.4219\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.4302\n",
      "Epoch 00074: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.2918 - accuracy: 0.4302 - val_loss: 0.2646 - val_accuracy: 0.3906\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.4709\n",
      "Epoch 00075: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3355 - accuracy: 0.4709 - val_loss: 0.2756 - val_accuracy: 0.3906\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.4070\n",
      "Epoch 00076: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3502 - accuracy: 0.4070 - val_loss: 0.2926 - val_accuracy: 0.3750\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.4593\n",
      "Epoch 00077: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.2767 - accuracy: 0.4593 - val_loss: 0.2822 - val_accuracy: 0.3750\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.4826\n",
      "Epoch 00078: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3062 - accuracy: 0.4826 - val_loss: 0.3345 - val_accuracy: 0.3906\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.3663\n",
      "Epoch 00079: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.2825 - accuracy: 0.3663 - val_loss: 0.3599 - val_accuracy: 0.3281\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.3895\n",
      "Epoch 00080: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.3256 - accuracy: 0.3895 - val_loss: 0.2825 - val_accuracy: 0.3750\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.4709\n",
      "Epoch 00081: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3110 - accuracy: 0.4709 - val_loss: 0.2293 - val_accuracy: 0.3906\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.4531\n",
      "Epoch 00082: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3190 - accuracy: 0.4531 - val_loss: 0.2991 - val_accuracy: 0.3906\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3039 - accuracy: 0.3895\n",
      "Epoch 00083: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3039 - accuracy: 0.3895 - val_loss: 0.3034 - val_accuracy: 0.3906\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.3779\n",
      "Epoch 00084: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2595 - accuracy: 0.3779 - val_loss: 0.2646 - val_accuracy: 0.4219\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.4651\n",
      "Epoch 00085: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.3160 - accuracy: 0.4651 - val_loss: 0.2750 - val_accuracy: 0.4219\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.4535\n",
      "Epoch 00086: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.2707 - accuracy: 0.4535 - val_loss: 0.3119 - val_accuracy: 0.3750\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.4419\n",
      "Epoch 00087: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3307 - accuracy: 0.4419 - val_loss: 0.2999 - val_accuracy: 0.3750\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.4244\n",
      "Epoch 00088: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2867 - accuracy: 0.4244 - val_loss: 0.2684 - val_accuracy: 0.3594\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.4219\n",
      "Epoch 00089: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2655 - accuracy: 0.4219 - val_loss: 0.2641 - val_accuracy: 0.3906\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.4709\n",
      "Epoch 00090: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.2951 - accuracy: 0.4709 - val_loss: 0.2644 - val_accuracy: 0.3906\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2792 - accuracy: 0.4244\n",
      "Epoch 00091: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2792 - accuracy: 0.4244 - val_loss: 0.2915 - val_accuracy: 0.3906\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.3953\n",
      "Epoch 00092: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2736 - accuracy: 0.3953 - val_loss: 0.2353 - val_accuracy: 0.4219\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2633 - accuracy: 0.4244\n",
      "Epoch 00093: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2633 - accuracy: 0.4244 - val_loss: 0.2892 - val_accuracy: 0.3750\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.4186\n",
      "Epoch 00094: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 982ms/step - loss: 0.3028 - accuracy: 0.4186 - val_loss: 0.2469 - val_accuracy: 0.3750\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3104 - accuracy: 0.4419\n",
      "Epoch 00095: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3104 - accuracy: 0.4419 - val_loss: 0.2359 - val_accuracy: 0.3906\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.4244\n",
      "Epoch 00096: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2413 - accuracy: 0.4244 - val_loss: 0.2500 - val_accuracy: 0.3906\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.4593\n",
      "Epoch 00097: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3500 - accuracy: 0.4593 - val_loss: 0.2791 - val_accuracy: 0.4219\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.4128\n",
      "Epoch 00098: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3050 - accuracy: 0.4128 - val_loss: 0.2806 - val_accuracy: 0.4062\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.3837\n",
      "Epoch 00099: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2794 - accuracy: 0.3837 - val_loss: 0.2997 - val_accuracy: 0.4062\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.4070\n",
      "Epoch 00100: val_accuracy did not improve from 0.45312\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.2848 - accuracy: 0.4070 - val_loss: 0.2978 - val_accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    traininAugmentation.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch = len(X_train) // 32,\n",
    "    validation_data = validationAugmentation.flow(X_test,y_test),\n",
    "    validation_steps = len(X_test) // 32,\n",
    "    epochs = 100, callbacks = [es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 465ms/step - loss: 0.2830 - accuracy: 0.3913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28295931220054626, 0.3913043439388275]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
